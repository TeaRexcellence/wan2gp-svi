diff --git a/wgp.py b/wgp.py
index c0acb56..fad0889 100644
--- a/wgp.py
+++ b/wgp.py
@@ -602,6 +602,10 @@ def validate_settings(state, model_type, single_prompt, inputs):
     sliding_window_size = inputs["sliding_window_size"]
     sliding_window_overlap = inputs["sliding_window_overlap"]
     sliding_window_discard_last_frames = inputs["sliding_window_discard_last_frames"]
+    svi_mode = inputs.get("svi_mode", False)
+    svi_ref_pad_num = inputs.get("svi_ref_pad_num", 0)
+    svi_num_motion_frames = inputs.get("svi_num_motion_frames", 1)
+    svi_ref_pad_cfg = inputs.get("svi_ref_pad_cfg", False)  # If True, all motion frames get mask=1; if False, only first frame
     video_length = inputs["video_length"]
     num_inference_steps= inputs["num_inference_steps"]
     skip_steps_cache_type= inputs["skip_steps_cache_type"]
@@ -5059,6 +5063,10 @@ def generate_video(
     model_type,
     mode,
     plugin_data=None,
+    svi_mode=False,
+    svi_ref_pad_num=0,
+    svi_num_motion_frames=1,
+    svi_ref_pad_cfg=False,
 ):
 
 
@@ -5255,12 +5263,24 @@ def generate_video(
         if video_source is not None:
             current_video_length +=  sliding_window_overlap - 1
         sliding_window = current_video_length > sliding_window_size
-        reuse_frames = min(sliding_window_size - latent_size, sliding_window_overlap) 
+        reuse_frames = min(sliding_window_size - latent_size, sliding_window_overlap)
     else:
         sliding_window = False
         sliding_window_size = current_video_length
         reuse_frames = 0
 
+    # SVI Mode: Stable Video Infinity for infinite-length video generation
+    svi_random_ref_frame = None  # Store original reference frame for SVI mask padding
+    svi_num_motion_frames = int(svi_num_motion_frames)  # Ensure int for tensor slicing
+    svi_ref_pad_num = int(svi_ref_pad_num)  # Ensure int
+    if svi_mode:
+        print(f"[SVI Mode] Enabled with motion_frames={svi_num_motion_frames}, ref_pad_num={svi_ref_pad_num}")
+        # SVI uses clip-chaining with decoded frames, not latent overlap
+        # Force sliding window behavior for multi-clip generation
+        if sliding_window_size == 0:
+            sliding_window_size = 81  # Default SVI clip size
+        sliding_window = current_video_length > sliding_window_size
+
     original_image_refs = image_refs
     image_refs = None if image_refs is None else ([] + image_refs) # work on a copy as it is going to be modified
     # image_refs = None
@@ -5460,8 +5480,14 @@ def generate_video(
                 break
             window_no += 1
             gen["window_no"] = window_no
-            return_latent_slice = None 
-            if reuse_frames > 0:                
+
+            # SVI Mode: Use different seed for each window to prevent repetitive patterns
+            if svi_mode and window_no > 1:
+                seed = set_seed(-1)
+                print(f"[SVI Mode] Window {window_no}: Using new seed {seed}")
+
+            return_latent_slice = None
+            if reuse_frames > 0:
                 return_latent_slice = slice(-(reuse_frames - 1 + discard_last_frames ) // latent_size - 1, None if discard_last_frames == 0 else -(discard_last_frames // latent_size) )
             refresh_preview  = {"image_guide" : image_guide, "image_mask" : image_mask} if image_mode >= 1 else {}
 
@@ -5837,6 +5863,10 @@ def generate_video(
                     pace=pace,
                     temperature=temperature,
                     window_start_frame_no = window_start_frame,
+                    svi_mode = svi_mode,
+                    svi_ref_pad_num = svi_ref_pad_num,
+                    svi_random_ref_frame = svi_random_ref_frame,
+                    svi_ref_pad_cfg = svi_ref_pad_cfg,
                 )
             except Exception as e:
                 if len(control_audio_tracks) > 0 or len(source_audio_tracks) > 0:
@@ -5926,7 +5956,26 @@ def generate_video(
                         if generated_audio is not None:
                             generated_audio = truncate_audio(generated_audio, 0, discard_last_frames, fps, audio_sampling_rate)
 
-                    if reuse_frames == 0:
+                    # SVI Mode: Use clip chaining with decoded frames instead of latent overlap
+                    if svi_mode:
+                        # Store the original reference frame for VAE padding (only on first window)
+                        if window_no == 1 and svi_random_ref_frame is None:
+                            svi_random_ref_frame = sample[:, 0].clone()
+
+                        # Extract last N motion frames as conditioning for next clip
+                        # This is the core SVI clip-chaining mechanism
+                        pre_video_guide = sample[:, -svi_num_motion_frames:].clone()
+
+                        # For SVI: discard motion frames from output (except final clip)
+                        # This prevents frame duplication at clip boundaries
+                        if window_no < total_windows:
+                            sample = sample[:, :-svi_num_motion_frames]
+                            guide_start_frame -= svi_num_motion_frames
+
+                        # SVI doesn't use latent overlap - set to None
+                        overlapped_latents = None
+                        print(f"[SVI Mode] Clip {window_no}/{total_windows} complete, chaining with {svi_num_motion_frames} motion frame(s)")
+                    elif reuse_frames == 0:
                         pre_video_guide =  sample[:,max_source_video_frames :].clone()
                     else:
                         pre_video_guide =  sample[:, -reuse_frames:].clone()
@@ -5938,10 +5987,11 @@ def generate_video(
                     guide_start_frame -= source_video_overlap_frames_count 
                     if generated_audio is not None:
                         generated_audio = truncate_audio(generated_audio, source_video_overlap_frames_count, 0, fps, audio_sampling_rate)
-                elif sliding_window and window_no > 1 and reuse_frames > 0:
+                elif sliding_window and window_no > 1 and reuse_frames > 0 and not svi_mode:
                     # remove sliding window overlapped frames at the beginning of the generation
+                    # Skip for SVI mode - motion frames already handled above
                     sample = sample[: , reuse_frames:]
-                    guide_start_frame -= reuse_frames 
+                    guide_start_frame -= reuse_frames
                     if generated_audio is not None:
                         generated_audio = truncate_audio(generated_audio, reuse_frames, 0, fps, audio_sampling_rate)
 
@@ -7737,6 +7787,10 @@ def save_inputs(
             sliding_window_color_correction_strength,
             sliding_window_overlap_noise,
             sliding_window_discard_last_frames,
+            svi_mode,
+            svi_ref_pad_num,
+            svi_num_motion_frames,
+            svi_ref_pad_cfg,
             image_refs_relative_size,
             remove_background_images_ref,
             temporal_upsampling,
@@ -9331,6 +9385,12 @@ def generate_video_tab(update_form = False, state_dict = None, ui_defaults = Non
                             sliding_window_overlap_noise = gr.Slider(0, 150, value=ui_get("sliding_window_overlap_noise",20 if vace else 0), step=1, label="Noise to be added to overlapped frames to reduce blur effect" , visible = vace, show_reset_button= False)
                             sliding_window_discard_last_frames = gr.Slider(0, 20, value=ui_get("sliding_window_discard_last_frames"), step=4, label="Discard Last Frames of a Window (that may have bad quality)", visible = True, show_reset_button= False)
 
+                        # SVI (Stable Video Infinity) hidden parameters - loaded from profile JSON
+                        svi_mode = gr.Checkbox(value=ui_get("svi_mode", False), visible=False)
+                        svi_ref_pad_num = gr.Number(value=ui_get("svi_ref_pad_num", 0), visible=False)
+                        svi_num_motion_frames = gr.Number(value=ui_get("svi_num_motion_frames", 1), visible=False)
+                        svi_ref_pad_cfg = gr.Checkbox(value=ui_get("svi_ref_pad_cfg", False), visible=False)
+
                         video_prompt_type_alignment = gr.Dropdown(
                             choices=[
                                 ("Aligned to the beginning of the Source Video", ""),
